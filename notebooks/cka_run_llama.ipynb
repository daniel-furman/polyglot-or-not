{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Am_Ubq6xTaBz"
      },
      "source": [
        "# Contrastive Knowledge Assesment (CKA) Notebook for LLaMa ü¶ôü¶ô\n",
        "This notebook enables interactive experimentation with CKA for `LLaMa` models.\n",
        "The goal is to probe if factual statements are predicted at a higher probability than a given counterfactuals.\n",
        "\n",
        "<a target=\"_blank\" href=\"https://colab.research.google.com/github/daniel-furman/Capstone/blob/main/notebooks/cka_run_llama.ipynb\">\n",
        "  <img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/>\n",
        "</a>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uccv2X7WeJGv"
      },
      "source": [
        "## Dependencies"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "41HkTUkbi9p1",
        "outputId": "28c85b2c-9c89-468e-a401-a9e5c172c0c3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A4gro-sOZz-O",
        "outputId": "7064906c-933d-4179-c7a3-11b465972d0d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'Capstone'...\n",
            "remote: Enumerating objects: 502, done.\u001b[K\n",
            "remote: Counting objects: 100% (159/159), done.\u001b[K\n",
            "remote: Compressing objects: 100% (90/90), done.\u001b[K\n",
            "remote: Total 502 (delta 74), reused 127 (delta 46), pack-reused 343\u001b[K\n",
            "Receiving objects: 100% (502/502), 24.32 MiB | 16.58 MiB/s, done.\n",
            "Resolving deltas: 100% (236/236), done.\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/daniel-furman/Capstone.git"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qaXMJaroH_TI",
        "outputId": "6de639fc-660f-453f-d370-0aab36681ea7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting transformers\n",
            "  Cloning https://github.com/daniel-furman/transformers_llama (to revision llama_push) to /tmp/pip-install-2yr0xxvt/transformers_f2f9296e14664cd49d8a66857e96a9a8\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/daniel-furman/transformers_llama /tmp/pip-install-2yr0xxvt/transformers_f2f9296e14664cd49d8a66857e96a9a8\n",
            "  Resolved https://github.com/daniel-furman/transformers_llama to commit 2a262d782bb687342c9ae102e52894eb7232f768\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: numpy==1.22.4 in /usr/local/lib/python3.9/dist-packages (from -r /content/Capstone/requirements_llama.txt (line 1)) (1.22.4)\n",
            "Collecting sentencepiece==0.1.97\n",
            "  Downloading sentencepiece-0.1.97-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
            "\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m23.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: torch==1.13.1 in /usr/local/lib/python3.9/dist-packages (from -r /content/Capstone/requirements_llama.txt (line 3)) (1.13.1+cu116)\n",
            "Collecting accelerate==0.16.0\n",
            "  Downloading accelerate-0.16.0-py3-none-any.whl (199 kB)\n",
            "\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m199.7/199.7 KB\u001b[0m \u001b[31m25.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting bitsandbytes==0.37.0\n",
            "  Downloading bitsandbytes-0.37.0-py3-none-any.whl (76.3 MB)\n",
            "\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m76.3/76.3 MB\u001b[0m \u001b[31m22.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: tqdm in /usr/local/lib/python3.9/dist-packages (from -r /content/Capstone/requirements_llama.txt (line 7)) (4.65.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.9/dist-packages (from torch==1.13.1->-r /content/Capstone/requirements_llama.txt (line 3)) (4.5.0)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.9/dist-packages (from accelerate==0.16.0->-r /content/Capstone/requirements_llama.txt (line 5)) (5.4.8)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.9/dist-packages (from accelerate==0.16.0->-r /content/Capstone/requirements_llama.txt (line 5)) (23.0)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.9/dist-packages (from accelerate==0.16.0->-r /content/Capstone/requirements_llama.txt (line 5)) (6.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.9/dist-packages (from transformers->-r /content/Capstone/requirements_llama.txt (line 4)) (2022.6.2)\n",
            "Collecting tokenizers!=0.11.3,<0.14,>=0.11.1\n",
            "  Downloading tokenizers-0.13.2-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (7.6 MB)\n",
            "\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m7.6/7.6 MB\u001b[0m \u001b[31m113.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.9/dist-packages (from transformers->-r /content/Capstone/requirements_llama.txt (line 4)) (3.9.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.9/dist-packages (from transformers->-r /content/Capstone/requirements_llama.txt (line 4)) (2.25.1)\n",
            "Collecting huggingface-hub<1.0,>=0.11.0\n",
            "  Downloading huggingface_hub-0.13.1-py3-none-any.whl (199 kB)\n",
            "\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m199.2/199.2 KB\u001b[0m \u001b[31m26.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.9/dist-packages (from requests->transformers->-r /content/Capstone/requirements_llama.txt (line 4)) (2.10)\n",
            "Requirement already satisfied: chardet<5,>=3.0.2 in /usr/local/lib/python3.9/dist-packages (from requests->transformers->-r /content/Capstone/requirements_llama.txt (line 4)) (4.0.0)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.9/dist-packages (from requests->transformers->-r /content/Capstone/requirements_llama.txt (line 4)) (1.26.14)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.9/dist-packages (from requests->transformers->-r /content/Capstone/requirements_llama.txt (line 4)) (2022.12.7)\n",
            "Building wheels for collected packages: transformers\n",
            "  Building wheel for transformers (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for transformers: filename=transformers-4.27.0.dev0-py3-none-any.whl size=6688316 sha256=9a040426e65e8a1a14f1149d1aaa48e0af73fa637013d73eb78b820f6c1fa75c\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-bjyrdtl5/wheels/1b/2a/c3/8a5ddf87ee8af113dedfb61c092a7f0ae6d9acf23c8d0481b3\n",
            "Successfully built transformers\n",
            "Installing collected packages: tokenizers, sentencepiece, bitsandbytes, huggingface-hub, accelerate, transformers\n",
            "Successfully installed accelerate-0.16.0 bitsandbytes-0.37.0 huggingface-hub-0.13.1 sentencepiece-0.1.97 tokenizers-0.13.2 transformers-4.27.0.dev0\n"
          ]
        }
      ],
      "source": [
        "!pip install -r /content/Capstone/requirements_llama.txt"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3yjnEaRtKd8L"
      },
      "source": [
        "## Imports"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "IJQImaEDTRMr"
      },
      "outputs": [],
      "source": [
        "import os"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "0jQTcgbNk-iA"
      },
      "outputs": [],
      "source": [
        "os.chdir('/content/Capstone/src/cka_scripts')\n",
        "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2' "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j6lqNVBmhW-g"
      },
      "source": [
        "## CLI usage"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1D4NDgkf8oAO",
        "outputId": "fce6bdeb-f67d-40db-9d2a-0f5b46a9a1cf"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CKA for /content/drive/MyDrive/Colab Files/llama/LLaMA/int8/llama-7b/\n",
            "Loading  model...\n",
            "Overriding torch_dtype=None with `torch_dtype=torch.float16` due to requirements of `bitsandbytes` to enable model loading in mixed int8. Either pass torch_dtype=torch.float16 or don't pass this argument at all to remove this warning.\n",
            "\n",
            "===================================BUG REPORT===================================\n",
            "Welcome to bitsandbytes. For bug reports, please submit your error trace to: https://github.com/TimDettmers/bitsandbytes/issues\n",
            "================================================================================\n",
            "Loading checkpoint shards: 100% 33/33 [04:52<00:00,  8.86s/it]\n",
            "Running comparisons...\n",
            "100% 21919/21919 [3:09:12<00:00,  1.93it/s]\n",
            "Done\n",
            "\n",
            "\n",
            "Score dict summary:\n",
            "{'/content/drive/mydrive/colab files/llama/llama/int8/llama-7b/': 'This model predicted 19440/21919 facts at a higher prob than the given counterfactual. The mean p_true / (p_true + p_false) was 0.8647 while the mean p_true was 0.1348'}\n"
          ]
        }
      ],
      "source": [
        "!python run_cka.py configs.rome_full.llama_rome_full"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8WXwAZfHMgAY"
      },
      "source": [
        "## Notebook usage"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "GVCMUZJXV0mq"
      },
      "outputs": [],
      "source": [
        "from run_cka import main"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PFy4ijAPc_mS"
      },
      "source": [
        "### gpt2 example with \"verbosity\" turned on"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "cebcf81481a546f59c60c5613feefc7e",
            "23abf6bde09745f789e8c9fee1e886a7",
            "b559b01279174e04a0b2132a8b822728",
            "c44403aa0faf4b45ad17eae85651d517",
            "c17f9b0629544cf683632c96e81e714c",
            "4c93d33542744ecabb5e19ff9d567fba",
            "295726e017e143a4ac3f652973605c99",
            "2f3da1ad97d242b2adcb03f9e9a842aa",
            "77383ac0588144e68aeae14d4dbad4f2",
            "e95e53c07bf347af913b910386930612",
            "b5f547122fe64217b39e8b821195314e"
          ]
        },
        "id": "fXTO0xG4Zzx5",
        "outputId": "48a34711-0e81-4fbb-eb95-e8b6b01936b7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Overriding torch_dtype=None with `torch_dtype=torch.float16` due to requirements of `bitsandbytes` to enable model loading in mixed int8. Either pass torch_dtype=torch.float16 or don't pass this argument at all to remove this warning.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CKA for /content/drive/MyDrive/Colab Files/llama/LLaMA/int8/llama-7b/\n",
            "Loading  model...\n",
            "\n",
            "===================================BUG REPORT===================================\n",
            "Welcome to bitsandbytes. For bug reports, please submit your error trace to: https://github.com/TimDettmers/bitsandbytes/issues\n",
            "================================================================================\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Loading checkpoint shards:   0%|          | 0/33 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "cebcf81481a546f59c60c5613feefc7e"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Running comparisons...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 0/3 [00:00<?, ?it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\tcontext... The 2020 Olympics were held in\n",
            "\ttokenized_context ids... tensor([[    1,   450, 29871, 29906, 29900, 29906, 29900, 16373,   892,  4934,\n",
            "           297]], device='cuda:0')\n",
            "\tdecoded tokenized_context... The 2020 Olympics were held in\n",
            "\tdecoded target id... Tokyo\n",
            "\tmost probable prediction id decoded... Tokyo\n",
            "\n",
            "\n",
            "\tcontext... The 2020 Olympics were held in\n",
            "\ttokenized_context ids... tensor([[    1,   450, 29871, 29906, 29900, 29906, 29900, 16373,   892,  4934,\n",
            "           297]], device='cuda:0')\n",
            "\tdecoded tokenized_context... The 2020 Olympics were held in\n",
            "\tdecoded target id... London\n",
            "\tmost probable prediction id decoded... Tokyo\n",
            "\n",
            "\n",
            "\tcontext... The 2020 Olympics were held in\n",
            "\ttokenized_context ids... tensor([[    1,   450, 29871, 29906, 29900, 29906, 29900, 16373,   892,  4934,\n",
            "           297]], device='cuda:0')\n",
            "\tdecoded tokenized_context... The 2020 Olympics were held in\n",
            "\tdecoded target id... Tokyo\n",
            "\tmost probable prediction id decoded... Tokyo\n",
            "\n",
            "\n",
            "\tcontext... The 2020 Olympics were held in\n",
            "\ttokenized_context ids... tensor([[    1,   450, 29871, 29906, 29900, 29906, 29900, 16373,   892,  4934,\n",
            "           297]], device='cuda:0')\n",
            "\tdecoded tokenized_context... The 2020 Olympics were held in\n",
            "\tdecoded target id... Berlin\n",
            "\tmost probable prediction id decoded... Tokyo\n",
            "\n",
            "\n",
            "\tcontext... The 2020 Olympics were held in\n",
            "\ttokenized_context ids... tensor([[    1,   450, 29871, 29906, 29900, 29906, 29900, 16373,   892,  4934,\n",
            "           297]], device='cuda:0')\n",
            "\tdecoded tokenized_context... The 2020 Olympics were held in\n",
            "\tdecoded target id... Tokyo\n",
            "\tmost probable prediction id decoded... Tokyo\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 33%|‚ñà‚ñà‚ñà‚ñé      | 1/3 [00:02<00:04,  2.30s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\tcontext... The 2020 Olympics were held in\n",
            "\ttokenized_context ids... tensor([[    1,   450, 29871, 29906, 29900, 29906, 29900, 16373,   892,  4934,\n",
            "           297]], device='cuda:0')\n",
            "\tdecoded tokenized_context... The 2020 Olympics were held in\n",
            "\tdecoded target id... Chicago\n",
            "\tmost probable prediction id decoded... Tokyo\n",
            "\n",
            "\n",
            "\tcontext... Operation Overlord took place in\n",
            "\ttokenized_context ids... tensor([[    1, 20462,  6811, 29880,   536,  3614,  2058,   297]],\n",
            "       device='cuda:0')\n",
            "\tdecoded tokenized_context... Operation Overlord took place in\n",
            "\tdecoded target id... Norm\n",
            "\tmost probable prediction id decoded... June\n",
            "\n",
            "\n",
            "\tcontext... Operation Overlord took place in\n",
            "\ttokenized_context ids... tensor([[    1, 20462,  6811, 29880,   536,  3614,  2058,   297]],\n",
            "       device='cuda:0')\n",
            "\tdecoded tokenized_context... Operation Overlord took place in\n",
            "\tdecoded target id... Man\n",
            "\tmost probable prediction id decoded... June\n",
            "\n",
            "\n",
            "\tcontext... Operation Overlord took place in\n",
            "\ttokenized_context ids... tensor([[    1, 20462,  6811, 29880,   536,  3614,  2058,   297]],\n",
            "       device='cuda:0')\n",
            "\tdecoded tokenized_context... Operation Overlord took place in\n",
            "\tdecoded target id... Norm\n",
            "\tmost probable prediction id decoded... June\n",
            "\n",
            "\n",
            "\tcontext... Operation Overlord took place in\n",
            "\ttokenized_context ids... tensor([[    1, 20462,  6811, 29880,   536,  3614,  2058,   297]],\n",
            "       device='cuda:0')\n",
            "\tdecoded tokenized_context... Operation Overlord took place in\n",
            "\tdecoded target id... Santiago\n",
            "\tmost probable prediction id decoded... June\n",
            "\n",
            "\n",
            "\tcontext... Operation Overlord took place in\n",
            "\ttokenized_context ids... tensor([[    1, 20462,  6811, 29880,   536,  3614,  2058,   297]],\n",
            "       device='cuda:0')\n",
            "\tdecoded tokenized_context... Operation Overlord took place in\n",
            "\tdecoded target id... Norm\n",
            "\tmost probable prediction id decoded... June\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 2/3 [00:03<00:01,  1.85s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\tcontext... Operation Overlord took place in\n",
            "\ttokenized_context ids... tensor([[    1, 20462,  6811, 29880,   536,  3614,  2058,   297]],\n",
            "       device='cuda:0')\n",
            "\tdecoded tokenized_context... Operation Overlord took place in\n",
            "\tdecoded target id... Bag\n",
            "\tmost probable prediction id decoded... June\n",
            "\n",
            "\n",
            "\tcontext... Steve Jobs is the founder of\n",
            "\ttokenized_context ids... tensor([[    1, 13981, 17163, 29879,   338,   278, 25331,   310]],\n",
            "       device='cuda:0')\n",
            "\tdecoded tokenized_context... Steve Jobs is the founder of\n",
            "\tdecoded target id... Apple\n",
            "\tmost probable prediction id decoded... Apple\n",
            "\n",
            "\n",
            "\tcontext... Steve Jobs is the founder of\n",
            "\ttokenized_context ids... tensor([[    1, 13981, 17163, 29879,   338,   278, 25331,   310]],\n",
            "       device='cuda:0')\n",
            "\tdecoded tokenized_context... Steve Jobs is the founder of\n",
            "\tdecoded target id... Microsoft\n",
            "\tmost probable prediction id decoded... Apple\n",
            "\n",
            "\n",
            "\tcontext... Steve Jobs is the founder of\n",
            "\ttokenized_context ids... tensor([[    1, 13981, 17163, 29879,   338,   278, 25331,   310]],\n",
            "       device='cuda:0')\n",
            "\tdecoded tokenized_context... Steve Jobs is the founder of\n",
            "\tdecoded target id... Apple\n",
            "\tmost probable prediction id decoded... Apple\n",
            "\n",
            "\n",
            "\tcontext... Steve Jobs is the founder of\n",
            "\ttokenized_context ids... tensor([[    1, 13981, 17163, 29879,   338,   278, 25331,   310]],\n",
            "       device='cuda:0')\n",
            "\tdecoded tokenized_context... Steve Jobs is the founder of\n",
            "\tdecoded target id... Oracle\n",
            "\tmost probable prediction id decoded... Apple\n",
            "\n",
            "\n",
            "\tcontext... Steve Jobs is the founder of\n",
            "\ttokenized_context ids... tensor([[    1, 13981, 17163, 29879,   338,   278, 25331,   310]],\n",
            "       device='cuda:0')\n",
            "\tdecoded tokenized_context... Steve Jobs is the founder of\n",
            "\tdecoded target id... Apple\n",
            "\tmost probable prediction id decoded... Apple\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3/3 [00:05<00:00,  1.80s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\tcontext... Steve Jobs is the founder of\n",
            "\ttokenized_context ids... tensor([[    1, 13981, 17163, 29879,   338,   278, 25331,   310]],\n",
            "       device='cuda:0')\n",
            "\tdecoded tokenized_context... Steve Jobs is the founder of\n",
            "\tdecoded target id... Intel\n",
            "\tmost probable prediction id decoded... Apple\n",
            "\n",
            "Done\n",
            "\n",
            "{'/content/drive/mydrive/colab files/llama/llama/int8/llama-7b/': [{\"The 2020 Olympics were held in ['Tokyo', 'London']\": {'p_true': 0.6943359375, 'p_false': 0.007415771484375, 'p_true - p_false': 0.686920166015625, 'p_true > p_false': 'True', 'p_true / (p_true + p_false)': 0.9894324712234297}}, {\"The 2020 Olympics were held in ['Tokyo', 'Berlin']\": {'p_true': 0.6943359375, 'p_false': 0.0004086494445800781, 'p_true - p_false': 0.6939272880554199, 'p_true > p_false': 'True', 'p_true / (p_true + p_false)': 0.9994117846380132}}, {\"The 2020 Olympics were held in ['Tokyo', 'Chicago']\": {'p_true': 0.6943359375, 'p_false': 0.0005087852478027344, 'p_true - p_false': 0.6938271522521973, 'p_true > p_false': 'True', 'p_true / (p_true + p_false)': 0.9992677569191742}}, {\"Operation Overlord took place in ['Normandy', 'Manila']\": {'p_true': 0.1590576171875, 'p_false': 6.431341171264648e-05, 'p_true - p_false': 0.15899330377578735, 'p_true > p_false': 'True', 'p_true / (p_true + p_false)': 0.999595760261153}}, {\"Operation Overlord took place in ['Normandy', 'Santiago']\": {'p_true': 0.1590576171875, 'p_false': 5.960464477539063e-08, 'p_true - p_false': 0.15905755758285522, 'p_true > p_false': 'True', 'p_true / (p_true + p_false)': 0.9999995623937065}}, {\"Operation Overlord took place in ['Normandy', 'Baghdad']\": {'p_true': 0.1590576171875, 'p_false': 1.3113021850585938e-06, 'p_true - p_false': 0.15905630588531494, 'p_true > p_false': 'True', 'p_true / (p_true + p_false)': 0.9999916930026216}}, {\"Steve Jobs is the founder of ['Apple', 'Microsoft']\": {'p_true': 0.6904296875, 'p_false': 0.00040984153747558594, 'p_true - p_false': 0.6900198459625244, 'p_true > p_false': 'True', 'p_true / (p_true + p_false)': 0.9994067341049317}}, {\"Steve Jobs is the founder of ['Apple', 'Oracle']\": {'p_true': 0.6904296875, 'p_false': 1.8417835235595703e-05, 'p_true - p_false': 0.6904112696647644, 'p_true > p_false': 'True', 'p_true / (p_true + p_false)': 0.9999733103258213}}, {\"Steve Jobs is the founder of ['Apple', 'Intel']\": {'p_true': 0.6904296875, 'p_false': 0.00014495849609375, 'p_true - p_false': 0.6902847290039062, 'p_true > p_false': 'True', 'p_true / (p_true + p_false)': 0.9997900755626707}}]}\n",
            "{'/content/drive/mydrive/colab files/llama/llama/int8/llama-7b/': [{\"The 2020 Olympics were held in ['Tokyo', 'London']\": {'p_true > p_false': 'True'}}, {\"The 2020 Olympics were held in ['Tokyo', 'Berlin']\": {'p_true > p_false': 'True'}}, {\"The 2020 Olympics were held in ['Tokyo', 'Chicago']\": {'p_true > p_false': 'True'}}, {\"Operation Overlord took place in ['Normandy', 'Manila']\": {'p_true > p_false': 'True'}}, {\"Operation Overlord took place in ['Normandy', 'Santiago']\": {'p_true > p_false': 'True'}}, {\"Operation Overlord took place in ['Normandy', 'Baghdad']\": {'p_true > p_false': 'True'}}, {\"Steve Jobs is the founder of ['Apple', 'Microsoft']\": {'p_true > p_false': 'True'}}, {\"Steve Jobs is the founder of ['Apple', 'Oracle']\": {'p_true > p_false': 'True'}}, {\"Steve Jobs is the founder of ['Apple', 'Intel']\": {'p_true > p_false': 'True'}}]}\n",
            "{'/content/drive/mydrive/colab files/llama/llama/int8/llama-7b/': 'This model predicted 9/9 facts at a higher prob than the given counterfactual. The mean p_true / (p_true + p_false) was 0.9985 while the mean p_true was 0.5146'}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "config = {\n",
        "    \"models\": [\n",
        "        \"/content/drive/MyDrive/Colab Files/llama/LLaMA/int8/llama-7b/\",\n",
        "    ],\n",
        "    \"input_information\": {\n",
        "        \"0\": {\n",
        "            \"stem\": \"The 2020 Olympics were held in\",\n",
        "            \"true\": \"Tokyo\",\n",
        "            \"false\": [\"London\", \"Berlin\", \"Chicago\"],\n",
        "        },\n",
        "        \"1\": {\n",
        "            \"stem\": \"Operation Overlord took place in\",\n",
        "            \"true\": \"Normandy\",\n",
        "            \"false\": [\"Manila\", \"Santiago\", \"Baghdad\"],\n",
        "        },\n",
        "        \"2\": {\n",
        "            \"stem\": \"Steve Jobs is the founder of\",\n",
        "            \"true\": \"Apple\",\n",
        "            \"false\": [\"Microsoft\", \"Oracle\", \"Intel\"],\n",
        "        },\n",
        "    },\n",
        "    \"verbosity\": True,\n",
        "}\n",
        "\n",
        "score_dicts = main(config)\n",
        "\n",
        "print(score_dicts[0])\n",
        "print(score_dicts[1])\n",
        "print(score_dicts[2])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "AGFcOIO0XU6O"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "machine_shape": "hm",
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "cebcf81481a546f59c60c5613feefc7e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_23abf6bde09745f789e8c9fee1e886a7",
              "IPY_MODEL_b559b01279174e04a0b2132a8b822728",
              "IPY_MODEL_c44403aa0faf4b45ad17eae85651d517"
            ],
            "layout": "IPY_MODEL_c17f9b0629544cf683632c96e81e714c"
          }
        },
        "23abf6bde09745f789e8c9fee1e886a7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4c93d33542744ecabb5e19ff9d567fba",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_295726e017e143a4ac3f652973605c99",
            "value": "Loading checkpoint shards: 100%"
          }
        },
        "b559b01279174e04a0b2132a8b822728": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2f3da1ad97d242b2adcb03f9e9a842aa",
            "max": 33,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_77383ac0588144e68aeae14d4dbad4f2",
            "value": 33
          }
        },
        "c44403aa0faf4b45ad17eae85651d517": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e95e53c07bf347af913b910386930612",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_b5f547122fe64217b39e8b821195314e",
            "value": " 33/33 [00:21&lt;00:00,  1.42it/s]"
          }
        },
        "c17f9b0629544cf683632c96e81e714c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4c93d33542744ecabb5e19ff9d567fba": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "295726e017e143a4ac3f652973605c99": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "2f3da1ad97d242b2adcb03f9e9a842aa": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "77383ac0588144e68aeae14d4dbad4f2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "e95e53c07bf347af913b910386930612": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b5f547122fe64217b39e8b821195314e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}